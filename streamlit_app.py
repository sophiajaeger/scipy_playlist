# -*- coding: utf-8 -*-
"""SciPy_project.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1JjtKUmI3eliCUWhmUHbeuKdOFJ3G2OXH

# **Analyzing music behaviour and predicting playlists**

Ideen:


*   three songs -> new ideas
*   load, preprocess data

*   streamlit app as input formular for extra criteria


  *   visualization and analysation
      *   features over the years (bmp, dancability, energy, valence, ...)
      *   bpm, dancability and valence (3D)
      * average length over the years (statistical analysis)
      *   bpm, dancability, liveness
      * distribution of key features (e.g., energy, danceability, acousticness) across different languages

* ML
  * clustering into genres (k means oder hierarchical clustering)
    * clustering using multiple audio features (using K-Means or Hierarchical Clustering) to identify different "types" of tracks that might not necessarily align with traditional genres
  * song prediction to 3 given songs (k nearest neighbors?)

Requirements to have installed:
 * kaggle
 * numpy  ?preinstalled
 * pandas ?preinstalled

# **Data description**
"""
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn.neighbors import NearestNeighbors
import streamlit as st
import seaborn as sns
import statsmodels.formula.api as smf
import statsmodels.api as sm
from statsmodels.stats.multicomp import pairwise_tukeyhsd

def streamlit_setup():
  st.set_page_config(
      page_title="Playlist Prediction",
      page_icon="â™«"
  )
  # display title and short explanation
  st.title("Welcome to our Playlist Prediction")
  st.write("where you might discover your new favorite songs!")

def load_dataframe(link):
# Download latest version
  #path = kagglehub.dataset_download(link)
  path = "spotify_tracks.csv"
  #print("Path to dataset files:", path)

  # Load the dataset
  #df = pd.read_csv(path+'/spotify_tracks.csv')
  df = pd.read_csv(path)

  # Display the first few rows
  df.head()
  return df

def preprocess_data(df):
  df = df.drop_duplicates(subset=['track_name','artist_name']) #deletes all row duplicates
  df = df.drop(['liveness','artwork_url','mode'], axis = 1) #delete the columns liveness, artwork_url and mode
  df = df[~(df == -1).any(axis=1)] #deletes all entries with values that are -1 (not existent)

  # rename track_id to spotify_id
  df = df.rename(columns={'track_id': 'spotify_id'})
  
  # generate a new column track-id with values from 0 to len(dataframe)
  df['track_id'] = range(len(df))
  return df

streamlit_setup()
df = load_dataframe("https://www.kaggle.com/gauthamvijayaraj/spotify-tracks-dataset-updated-every-week")
df = preprocess_data(df)
with st.expander("Data Description"):
    st.write("The dataset contains the following columns:", df.columns)
    st.write("The dataset contains", df.shape[0], "rows and", df.shape[1], "columns.")
    st.write("A few examples of the data are displayed below:")
    df.head()
    st.write("The columns include features such as danceability, energy, loudness, speechiness, acousticness, instrumentalness, valence, tempo, and popularity. The dataset also contains information about the track name, artist name, year, language, and the Spotify ID of the track.")

st.markdown("## Data analysis and visualization")

st.markdown("### 1) General data analysis")
with st.expander("General Data Analysis"):
  st.dataframe(df.describe(), use_container_width=True)
  st.write("This table gives us insights about the maximum and minimum values of a parameter, as well as statistical parameters like the mean which help to process the data correctly and use the parameters in a good manner for further analysis.")
#creating some histograms 
with st.expander("General visualization"):
  fig = plt.figure()
  gs = fig.add_gridspec(2, 2)
  ax1 = fig.add_subplot(gs[0, 0])
  ax2 = fig.add_subplot(gs[1, 0])
  ax3 = fig.add_subplot(gs[0, 1])
  ax4 = fig.add_subplot(gs[1, 1])

  ax1.hist(df['year'], bins = 50, color = "maroon", density = "True")
  ax1.set_xlabel("year")
  ax1.set_title("Song releases over the years")

  ax2.hist(df['danceability'], bins ='auto', color = "#D2665A",density = "True")
  ax2.set_xlabel("danceability")
  ax2.set_title("Distribution of danceability")

  ax3.hist(df['instrumentalness'], bins = 30, color = "#F2B28C",density = "True")
  ax3.set_xlabel("instrumentalness")
  ax3.set_title("Distribution of instrumentalness")

  ax4.hist(df['duration_ms'], bins = 50, color = "#F6DED8",density = "True")
  ax4.set_xlabel("song length in ms")
  ax4.set_title("Distribution of song length")
  fig.tight_layout()
  #plt.show()
  st.pyplot(fig)


  st.text("From the plotted graphs, we are able to draw the following conclusions:\n -the number of songs which were released each year increased over the last 50 years. Last year, the amount of released music was much higher than before.\n-Most of the songs have a dancability score between 0.4 and 0.8 \n-Nearly all songs have a very low instrumentalness score and are rather short. A low instumentalness score might be the result of nearly all songs having lyrics. Most of the songs have a length shorter than two minutes. This could be the case because white noise tracks/... are included")
  
st.markdown("### 2) Exploration of Cultural Patterns and Trends")

# plot for patterns over the years
with st.expander("Development of patterns over the year"):
  fig, ax1 = plt.subplots(figsize=(12, 8))
  sns.lineplot(data=df, x='year', y=df['tempo'], marker='o', label='Tempo', color='#D2665A', ax=ax1)
  ax1.set_ylabel('Tempo', color='#D2665A')
  ax1.tick_params(axis='y', labelcolor='#D2665A')
  ax2 = ax1.twinx()
  sns.lineplot(data=df, x='year', y=df['valence'] * 100, marker='o', label='Valence (*100)', color='#F2B28C', ax=ax2)
  ax2.set_ylabel('Valence (*100)', color='#F2B28C')
  ax2.tick_params(axis='y', labelcolor='#F2B28C')
  sns.lineplot(data=df, x='year', y=df['duration_ms'] / 6000, marker='o', label='Length (seconds)', color='#F6DED8', ax=ax2)
  ax1.set_xlabel('Year')
  plt.title('Music Attributes Over Years')

  # Show the plot
  #plt.tight_layout()
  #plt.show()
  st.pyplot(fig)

  st.text("In this plot, the distribution of the features Length of the song, Tempo and Valence can be investigated. We implemented two axis to integrate all three plots into one figure. Tempo is plotted with the use of the left axis while Valence and Length of the song are plotted with the help of the right axis. Especially for the parameter Valence, we can recognize strong changes over the years, with an overall decreasing tendency during the last 30 years. The same is true for Valence, while the parameter tempo stays more or less constant. ")
# check if there are statistically significant differences in the distribution of key features across languages using mixed linear effects models
with st.expander("Differences of features across languages"):
    features = ['tempo', 'danceability', 'speechiness', 'energy']
    colors = ["#AEC6CF", "#FFB347", "#77DD77", "#F49AC2"]
    
    # Create a 2x2 grid for the boxplots
    fig, axs = plt.subplots(2, 2, figsize=(12, 10))
    axs = axs.flatten()
    
    posthoc_results = {}
    for i, feature in enumerate(features):
        # Plot distribution of the feature across languages using a boxplot
        sns.boxplot(x='language', y=feature, data=df, ax=axs[i], color=colors[i])
        axs[i].set_title(f"{feature.capitalize()} by Language")
        axs[i].set_xlabel("Language")
        axs[i].set_ylabel(feature.capitalize())
        
        # Fit a linear model (ANOVA) with language as categorical
        model = smf.ols(formula=f"{feature} ~ C(language)", data=df).fit()
        anova_table = sm.stats.anova_lm(model, typ=2)
        p_val = anova_table.loc["C(language)", "PR(>F)"]
        
        # Perform pairwise post-hoc Tukey HSD test to identify pairwise differences
        tukey = pairwise_tukeyhsd(endog=df[feature], groups=df['language'], alpha=0.05)
        # Convert Tukey results to a DataFrame
        tukey_results = pd.DataFrame(data=tukey._results_table.data[1:], 
                                     columns=tukey._results_table.data[0])
        # Filter for comparisons that are statistically significant
        sig_comparisons = tukey_results[tukey_results['reject'] == True]
        posthoc_results[feature] = sig_comparisons
        
    fig.tight_layout()
    st.pyplot(fig)
    st.write("Here we can investigate the expression of different features (Tempo, Danceability, Speechiness and Energy) in the six different languages of the dataset. Below, the results of a pairwise comparison in form of the Tukey HSD Test are displayed for each feature. It has to be mentioned that only the pairs which lead to significant results are listed here. Interestingly, the significant differences are very high for the parameter Tempo (e.g Hindi/Korean or English/Korean) in comparison to the other parameters. There are more significant differences for the parameters Danceablity and Speechiness in contrast to Tempo and Energy. This leads to the conclusion that there are more inter-linguistic differences in the parameters Danceability and Speechiness opposed to Tempo and Energy.")
    st.markdown("#### Pairwise Comparisons (Tukey HSD Test)")
    for feature in features:
        st.markdown(f"**{feature.capitalize()}**")
        if posthoc_results[feature].empty:
            st.write("No statistically significant differences found between languages for this feature.")
        else:
            st.dataframe(posthoc_results[feature])
   # to do: analysize the p values and stuff

st.markdown("### 3) Correlation between features")
with st.expander("Dancability and acousticness"):
  fig, ax = plt.subplots()
  ax.scatter(x=df["danceability"]*100,y=df["popularity"],alpha = 0.09, color = "#7C444F")
  ax.set_xlabel("dancability in %")
  ax.set_ylabel("popularity in %")
  ax.set_title("Relation beween danceability and acousticness")
  ax.grid(True)
  fig.tight_layout()
  # plt.show()
  st.pyplot(fig)

  st.text("As the plot displays, the most popular songs have a medium or high danceability.\n Nevertheless, it is likely that the popularity does not only depend on the dancability.\n")
# plot to visualize song length
with st.expander("Song length per year"):
  fig, ax = plt.subplots()
  ax.scatter(x=df["year"],y=df["duration_ms"],alpha = 0.9, color = "#7C444F")
  ax.set_xlabel("year")
  ax.set_ylabel("song length")
  ax.set_title("Relation beween release year and song length")
  ax.grid(True)
  fig.tight_layout()
  # plt.show()
  st.pyplot(fig)
  st.write("There is an interesting correlation between year and number of song releases in that year. The number of song releases increased nearly exponentially in 2000-2020 but declined very fast after 2020. This can be connected to the development of new technology in the 21th century (increase) and the covid-pandemic in the last years (decline)")
with st.expander("Heatmap of feature correlations"):
  # Create a correlation matrix
  df_numerical = df.select_dtypes(include=[np.number])
  corr = df_numerical.corr().round(2)
  
  # Create a heatmap
  plt.figure(figsize=(10, 8))
  sns.heatmap(corr, annot=True, cmap='coolwarm', vmin=-1, vmax=1)
  
  # Set plot title
  plt.title('Correlation Matrix')
  
  # Show the plot
  #plt.show()
  st.pyplot(plt)
  st.text("With the help of this heatmap, we are able to infer which parameters in the data might me correlated and therefore interesting to further investigate. \n 1)Loudness/Energy has a high positive correlation.  The higher the volume of the song, the more energetic the is perceived to be. \n 2) Valence/Danceability has a high positive correlation. The happier the song makes a person feel, the more the person in motivated to dance to it \n 3) Acousticness/Energy has a high negative correlation. It seems to be the case that songs that are acoustic are perceived as less energetic \n 4)Tempo/Danceability does not have a correlation at all, indicating that the tempo of the song does not influence the ability to dance to it \n 5) The key the song is written in does not have an influence on valence, which is kind of suprising when we think about having major and minor chords which are normally linked to the emotional character of a song")
  # to do: write what we can draw from this

def contrast_coding(df, column_name):
    df[column_name] = df[column_name].astype('category')
    df[column_name] = df[column_name].cat.codes
    return df
# contrast coding the language column
df = contrast_coding(df, 'language')

# select relevant features for KNN
features = ['danceability', 'energy', 'loudness', 'speechiness', 'acousticness', 'instrumentalness', 'valence', 'tempo', 'language']
X = df[features].values

# Initialize and fit the KNN model
knn = NearestNeighbors(n_neighbors=13, algorithm='auto', metric='cosine')
knn.fit(X)

def recommend_songs(knn, song_ids):
    if not song_ids:
        return pd.DataFrame()

    # Find average feature vector for the input songs
    features = ['danceability', 'energy', 'loudness', 'speechiness', 'acousticness', 'instrumentalness', 'valence', 'tempo', 'language']
    avg_features = np.mean(df.loc[song_ids, features], axis=0)

    # Find k-nearest neighbors to average vector
    distances, ids = knn.kneighbors([avg_features], n_neighbors=13)

    # save ids in one dimensional array
    ids = ids.flatten()
    return ids


    # Return recommended song indices (excluding the input songs)
    recommended_ids = [i for i in ids[0] if i not in song_ids]
    recommended_songs = df.loc[recommended_ids, ['track_name', 'artist_name', 'year']]
    return recommended_songs

def label_preview(row):
    return f"{row['artist_name']} ({row['year']}): {row['track_name']}"
  
# Example usage in an interactive loop
st.markdown("## Playlist Prediction")
st.write("Please enter the names of three songs to get recommendations.")
#slider to limit the years of output songs
#slider_val = st.slider(

#checkbox_val = st.checkbox("Form checkbox")

selected_songs = []
for i in range(3):
  search_term = st.text_input(f"Enter the name of song {i+1}: ")
  
  # create a dataframe matching songs with the columns "track_title", "artist_name", "year" and its ID in the df
  matching_songs = df[df['track_name'].str.contains(search_term, case=False)]
  
  if matching_songs.empty:
      st.write("No matching songs found. Please try again.")
      continue
  
  # create a new column named preview that concatinates the columns "track_title" by "artist_name" in "year"
  matching_songs['preview'] = matching_songs.apply(label_preview, axis=1)

  # show options in st.multiselect in form Id: Song Name by artist in year and saves id in variable
  selected_preview = st.selectbox(
    label="Select one of the songs",
    options=matching_songs['preview'],
    key=f"song_{i}",
    placeholder="Select a song..."
    )

  #returning the index of selected_song_name in df
  selected_song_row = matching_songs.loc[matching_songs['preview'] == selected_preview, ['track_id']]
  selected_song_id = selected_song_row.iloc[0]['track_id']
  st.write("Selected song: ", selected_song_id, selected_preview)

  selected_songs.append(selected_song_id)

# check if 3 different songs were selected
if len(selected_songs) != 3:
  st.write("Please select three songs to continue.")
elif len(set(selected_songs)) != 3:
    st.write("Please select three different songs.")
else:
    with st.form(key='preselection_form'):
      years = st.slider("Select the years of the output songs", min_value=min(df['year']), max_value=max(df['year']), step=1, value=[min(df['year']), max(df['year'])])
                
      st.write("to do: more filters(same artist, country, exclude features, posssibly emphasize features)")
      submitted = st.form_submit_button("Generate Playlist")

    if submitted:
      recommended_song_ids = recommend_songs(knn, selected_songs)
      # copy the corresponding rows of the recommended songs from df into a new dataframe
      recommended_songs_df = df[df['track_id'].isin(recommended_song_ids)]
        
      if not recommended_songs_df.empty:
        #generate playlist
        # extract spotify ids from the recommended songs
        spotify_ids = recommended_songs_df['spotify_id'].tolist()

        for spotify_id in spotify_ids:
            embed_code = f"""
            <iframe src="https://open.spotify.com/embed/track/{spotify_id}" 
                    width="300" height="80" frameborder="0" allowtransparency="true" allow="encrypted-media">
            </iframe>
            """
            st.components.v1.html(embed_code, height=90)
      else:
        st.write("No recommendations found for this song.")
          
        st.write("Downloading data...")